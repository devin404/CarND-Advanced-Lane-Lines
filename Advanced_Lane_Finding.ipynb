{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing package\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import statistics\n",
    "import os\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare object points and image points for calibration\n",
    "\n",
    "#Array to strore img points and obj point\n",
    "objpoints = []\n",
    "imgpoints = []\n",
    "\n",
    "def calibrate():\n",
    "\n",
    "    nx = 9 #Number of inside corners in x\n",
    "    ny = 6 #Number of inside corners in y\n",
    "\n",
    "    #Object Points\n",
    "    objp = np.zeros((6*9,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "    \n",
    "    for fname in images:\n",
    "\n",
    "        img = cv2.imread(fname)\n",
    "\n",
    "        # Convert to grayscale\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "\n",
    "        # If found, update lists\n",
    "        if ret == True:\n",
    "\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            #cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Function to undistort\n",
    "\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sx_gradient_s_transform(img, s_thresh=(170, 255), sx_thresh=(50, 100)):\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    #color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "    \n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "    return combined_binary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def perspective_transform(img):\n",
    "    \n",
    "    img_size = (img.shape[1],img.shape[0])\n",
    "    \n",
    "    offset = 200\n",
    "    \n",
    "    src = np.float32([[550,478],[732,478],[1053,685],[246,685]])\n",
    "\n",
    "    dst = np.float32([[offset, offset], [img_size[0]-offset, offset], \n",
    "                                     [img_size[0]-offset, img_size[1]], \n",
    "                                     [offset, img_size[1]]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src,dst) \n",
    "    warped = np.copy(img)\n",
    "    warped = cv2.warpPerspective(warped,M,img_size, flags = cv2.INTER_LINEAR)\n",
    "\n",
    "        \n",
    "    return warped, src, dst\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect Lane Lines and Lane Boundaries\n",
    "\n",
    "\n",
    "def find_lane_pixels(binary_warped):\n",
    "    \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    \n",
    "    # Create an output image to draw on and visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    \n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # HYPERPARAMETERS\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(binary_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        ### Find the four below boundaries of the window ###\n",
    "        win_xleft_low = leftx_current - margin  \n",
    "        win_xleft_high = leftx_current + margin  \n",
    "        win_xright_low = rightx_current - margin \n",
    "        win_xright_high = rightx_current + margin  \n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),\n",
    "        (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),\n",
    "        (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        ### Identify the nonzero pixels in x and y within the window ###\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        ### If you found > minpix pixels, recenter next window ###\n",
    "        ### (`right` or `leftx_current`) on their mean position ###\n",
    "        \n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, out_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Search when you have a prior\n",
    "\n",
    "def fit_poly(img, leftx, lefty, rightx, righty):\n",
    "    ### Fit a second order polynomial to each with np.polyfit() ###\n",
    "    \n",
    "    global left_fit\n",
    "    global right_fit\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    ### Calc both polynomials using ploty, left_fit and right_fit ###\n",
    "    \n",
    "    try:\n",
    "        left_fit = np.polyfit(lefty,leftx,2)\n",
    "        right_fit = np.polyfit(righty,rightx,2)\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        #num_of_missed_frame = 0\n",
    "    except:\n",
    "        #print('The function failed to fit a line!')\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        pass\n",
    "        \n",
    "    return left_fitx, right_fitx, ploty\n",
    "\n",
    "def search_around_poly(binary_warped):\n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    # The quiz grader expects 100 here, but feel free to tune on your own!\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    ### Hint: consider the window areas for the similarly named variables ###\n",
    "    ### in the previous quiz, but change the windows to our new search area ###\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*nonzeroy**2 + left_fit[1]*nonzeroy + left_fit[2] - margin))\n",
    "                    & (nonzerox < (left_fit[0]*nonzeroy**2 + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*nonzeroy**2 + right_fit[1]*nonzeroy + right_fit[2] - margin))\n",
    "                    & (nonzerox < (right_fit[0]*nonzeroy**2 + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    if( (len(left_lane_inds) == 0) or (len(right_lane_inds) == 0)):\n",
    "        num_of_missed_frame = num_of_missed_frame + 1\n",
    "       \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Fit new polynomials\n",
    "    left_fitx, right_fitx, ploty = fit_poly(binary_warped, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    ## Visualization ##\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    window_img = np.zeros_like(out_img)\n",
    "    # Color in left and right line pixels\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "    # Generate a polygon to illustrate the search window area\n",
    "    # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "    left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "    left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                              ploty])))])\n",
    "    left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "    right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "    right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                              ploty])))])\n",
    "    right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "    cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "    result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    return result, left_fitx, right_fitx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature_real(leftx, rightx):\n",
    "    '''\n",
    "    Calculates the curvature of polynomial functions in meters.\n",
    "    '''\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/890 # meters per pixel in x dimension\n",
    "    \n",
    "    ploty = np.linspace(0, 719, num=720)   \n",
    "    left_fit_cr = np.polyfit(ploty * ym_per_pix, leftx * xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty * ym_per_pix, rightx * xm_per_pix, 2)\n",
    "    \n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "     # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = 719\n",
    "    \n",
    "    left_curverad = ((1+(2*left_fit_cr[0]*y_eval*ym_per_pix + left_fit_cr[1])**2)**(3/2))/(2*left_fit_cr[0])\n",
    "    \n",
    "    ## Implement the calculation of the left line here\n",
    "    right_curverad = ((1+(2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**(3/2))/(2*right_fit_cr[0])\n",
    "    \n",
    "    \n",
    "    left_lane_Bottom = (left_fit_cr[0] * ((y_eval*ym_per_pix)**2)) + (left_fit_cr[1] * (y_eval*ym_per_pix)) + left_fit_cr[2]\n",
    "    right_lane_Bottom = (right_fit_cr[0] * ((y_eval*ym_per_pix)**2)) + (right_fit_cr[1] * (y_eval*ym_per_pix)) + right_fit_cr[2]\n",
    "    \n",
    "#     mean_leftx = statistics.mean(left_fit_cr)\n",
    "#     mean_lefty = statistics.mean(left_fit_cr)\n",
    "#     centre_of_lane = (mean_leftx + mean_lefty)/2\n",
    "#     centre_of_frame = 640 # Image size 1280/2\n",
    "#     offset = (centre_of_frame - centre_of_lane) * xm_per_pix\n",
    "\n",
    "    centre_of_lane = (left_lane_Bottom + right_lane_Bottom)/2\n",
    "    centre_of_frame = 640 * xm_per_pix  # Image size 1280/2\n",
    "    offset = (centre_of_frame - centre_of_lane)\n",
    "    \n",
    "    return left_curverad, right_curverad, offset\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smoothning\n",
    "\n",
    "def smooth(prev, curr, coeficient = 0.4):\n",
    "\n",
    "    return curr*coeficient + prev*(1-coeficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "left_fit = []\n",
    "right_fit = []\n",
    "num_of_missed_frame = 0\n",
    "radius_of_curvature_previous = 0\n",
    "offset_previous = 0\n",
    "left_fit_previous = [0,0,0]\n",
    "right_fit_previous = [0,0,0]\n",
    "\n",
    "def process_image(image):\n",
    "    \n",
    "    global left_fit\n",
    "    global right_fit\n",
    "    global num_of_missed_frame\n",
    "    global radius_of_curvature_previous\n",
    "    global offset_previous\n",
    "    global left_fit_previous\n",
    "    global right_fit_previous\n",
    "    \n",
    "    if num_of_missed_frame == 5: #Reset if 5 frames are missed\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped_image)\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        left_fit_previous = left_fit\n",
    "        right_fit_previous = right_fit\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        lane_image, left_fitx, right_fitx = search_around_poly(binary_warped_image)\n",
    "        num_of_missed_frame = 0\n",
    "        \n",
    "    if not imgpoints:\n",
    "        calibrate()\n",
    "\n",
    "    ploty = np.linspace(0, 719, num=720)    \n",
    "        \n",
    "    #image = mpimg.imread('./test_images/test6.jpg')\n",
    "    undistort_image = cal_undistort(image, objpoints, imgpoints)\n",
    "    combined_binary_image = sx_gradient_s_transform(undistort_image)\n",
    "    binary_warped_image, src, dst = perspective_transform(combined_binary_image)\n",
    "    \n",
    "    if (len(left_fit) == 0) or (len(right_fit)==0):\n",
    "        leftx, lefty, rightx, righty, out_img = find_lane_pixels(binary_warped_image)\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "        left_fit_previous = left_fit\n",
    "        right_fit_previous = right_fit\n",
    "        lane_image, left_fitx, right_fitx = search_around_poly(binary_warped_image)\n",
    "    else:\n",
    "        lane_image, left_fitx, right_fitx = search_around_poly(binary_warped_image)\n",
    "        \n",
    "    \n",
    "    warped = cv2.cvtColor(lane_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    left_curverad, right_curverad, offset = measure_curvature_real(left_fitx, right_fitx)\n",
    "    \n",
    "    radius_of_curvature_current = (left_curverad + right_curverad)/2\n",
    "    radius_of_curvature = smooth(radius_of_curvature_previous,radius_of_curvature_current)\n",
    "    radius_of_curvature_previous = radius_of_curvature\n",
    "    \n",
    "    offset = smooth(offset_previous,offset)\n",
    "    offset_previous = offset\n",
    "    \n",
    "    left_fit[0]= smooth(left_fit_previous[0],left_fit[0])\n",
    "    left_fit_previous[0] = left_fit[0]\n",
    "    \n",
    "    left_fit[1]= smooth(left_fit_previous[1],left_fit[1])\n",
    "    left_fit_previous[1] = left_fit[1]\n",
    "    \n",
    "    left_fit[2]= smooth(left_fit_previous[2],left_fit[2])\n",
    "    left_fit_previous[2] = left_fit[2]\n",
    "    \n",
    "    \n",
    "    right_fit[0]= smooth(right_fit_previous[0],right_fit[0])\n",
    "    right_fit_previous[0] = right_fit[0]\n",
    "    \n",
    "    right_fit[1]= smooth(right_fit_previous[1],right_fit[1])\n",
    "    right_fit_previous[1] = right_fit[1]\n",
    "    \n",
    "    right_fit[2]= smooth(right_fit_previous[2],right_fit[2])\n",
    "    right_fit_previous[2] = right_fit[2]\n",
    "    \n",
    "    \n",
    "    #Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    Minv = cv2.getPerspectiveTransform(dst,src) \n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (image.shape[1], image.shape[0])) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undistort_image, 1, newwarp, 0.3, 0)\n",
    "\n",
    "    cv2.putText(result,'RADIUS OF CURVATURE',(10,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),1)\n",
    "    cv2.putText(result,str(round(radius_of_curvature, 2)),(450,50),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),1)\n",
    "    cv2.putText(result,'OFFSET',(10,100),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),1)\n",
    "    cv2.putText(result,str(round(offset, 2)),(190,100),cv2.FONT_HERSHEY_COMPLEX,1,(255,0,0),1)\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video Output_Video/project_video.mp4\n",
      "[MoviePy] Writing video Output_Video/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [27:21<00:01,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: Output_Video/project_video.mp4 \n",
      "\n",
      "CPU times: user 25min 3s, sys: 15.3 s, total: 25min 18s\n",
      "Wall time: 27min 24s\n"
     ]
    }
   ],
   "source": [
    "#Test Video\n",
    "\n",
    "white_output = 'Output_Video/project_video.mp4'\n",
    "## To speed up the testing process you may want to try your pipeline on a shorter subclip of the video\n",
    "## To do so add .subclip(start_second,end_second) to the end of the line below\n",
    "## Where start_second and end_second are integer values representing the start and end of the subclip\n",
    "## You may also uncomment the following line for a subclip of the first 5 seconds\n",
    "#clip1 = VideoFileClip(\"./project_video.mp4\").subclip(0,3)\n",
    "clip1 = VideoFileClip(\"./project_video.mp4\")\n",
    "white_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time white_clip.write_videofile(white_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'HTML' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-68061e453756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m HTML(\"\"\"\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0mvideo\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"960\"\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"540\"\u001b[0m \u001b[0mcontrols\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;34m<\u001b[0m\u001b[0msource\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"{0}\"\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m<\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvideo\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \"\"\".format(white_output))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'HTML' is not defined"
     ]
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
